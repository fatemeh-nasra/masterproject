{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f069ef5e-20bb-4ff1-a9cf-302945d113a3",
   "metadata": {},
   "source": [
    "# Notebook for Fatemeh to run Differentiall Accessibility Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739b823-54a8-4d78-b0c7-8a2c18d464e9",
   "metadata": {},
   "source": [
    "Use conda env with snapatac, polars, numpy, scanpy, pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f14435-92eb-4795-b436-1881ff536de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snapatac2 as snap\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import polars as pl \n",
    "import os\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f5b3e-58cd-4500-bf11-135e7d49856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset(data, path, sep='\\t', header=True, index=True, compression=None):\n",
    "    \"\"\"\n",
    "    See pandas.to_csv documentation - this is just a wrapper\n",
    "    :param data: data to save\n",
    "    :param path: str or Path object, path to save\n",
    "    :param sep:\n",
    "    :param header:\n",
    "    :param index:\n",
    "    :param compression:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "\n",
    "    if isinstance(path, str):\n",
    "        path = Path(path)\n",
    "\n",
    "    output_dir = path.parents[0]\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return data.to_csv(\n",
    "        path, sep=sep, header=header, index=index, compression=compression\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380bf742-4d5f-4323-ab40-37df3859af05",
   "metadata": {},
   "source": [
    "## Step 1. Preprocessing of each ATAC object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfaedb8-d2e9-424c-8923-4fc48c9f6183",
   "metadata": {},
   "source": [
    "Unfortunately ATAC data do not look like RNA data, they do not have nice set of genes, same for all samples in the world. We cannot integrate several ATAC objects because they carry different features. That's why we need first to make ATAC features same across different samples. To do this I have this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5ef0b-2a7f-4ac4-8514-f2f5420b7467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample_id, gene_matrix_path, atac_fragments_path, output_snap_path, temp_dir=\"/scratch/alexandra.livanova/INT/tmpdir\"):\n",
    "    \"\"\"\n",
    "    Process a single sample for integration.\n",
    "    \n",
    "    Parameters:\n",
    "        sample_id (str): Sample identifier.\n",
    "        gene_matrix_path (str): Path to the gene matrix `.h5ad` file (your gene matrix with cell annotation)\n",
    "        atac_fragments_path (str): Path to the atac_fragments.tsv.gz file (also cellranger output)\n",
    "        output_snap_path (str): Path to save the processed snap `.h5ad` file\n",
    "        cell_type (str): Cell type to filter in the whitelist\n",
    "        temp_dir (str): Temporary directory for snap.pp.import_data.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Read gene matrix with annotated cells\n",
    "    gene_matrix = sc.read(gene_matrix_path)\n",
    "    \n",
    "    # Decompress atac_fragments.tsv.gz\n",
    "\n",
    "    atac_fragments_decompressed = atac_fragments_path.rstrip('.gz')\n",
    "    if not os.path.exists(atac_fragments_decompressed):\n",
    "        print(f\"{atac_fragments_decompressed} does not exist. Decompressing...\")\n",
    "        os.system(f\"gunzip {atac_fragments_path}\")\n",
    "    else:\n",
    "        print(f\"{atac_fragments_decompressed} already exists. Skipping decompression.\")\n",
    "\n",
    "    \n",
    "    # Import data using SnapATAC\n",
    "    print(\"start creating snap object\")\n",
    "    data = snap.pp.import_data(\n",
    "        atac_fragments_decompressed,\n",
    "        chrom_sizes=snap.genome.hg38,\n",
    "        file=output_snap_path,\n",
    "        sorted_by_barcode=False,\n",
    "        whitelist=gene_matrix.obs[gene_matrix.obs['celltype_from_atac']=='Tumor cells'].index.tolist(), # here I select tumor cells only, ATAC object will have smaller size\n",
    "        tempdir=temp_dir\n",
    "    )\n",
    "    \n",
    "    # Add tile matrix\n",
    "    snap.pp.add_tile_matrix(data)\n",
    "    data.close()\n",
    "    print(\"snap object is done\")\n",
    "    \n",
    "    # Reload and add metadata\n",
    "    data = sc.read(output_snap_path)\n",
    "    data.obs['patient'] = sample_id # here I add patient id\n",
    "    data.obs['celltype_from_atac'] = gene_matrix.obs['celltype_from_atac'].reindex(data.obs_names) #here I create a column with cell annotation, will be Tumor cells only in my case\n",
    "    data.write(output_snap_path) #save your object\n",
    "    \n",
    "    # Recompress atac_fragments.tsv\n",
    "    os.system(f\"gzip {atac_fragments_decompressed}\")\n",
    "    print(f\"Processing of {sample_id} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d706eb9-96b3-4d4a-a7c2-8dffad5f4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample-specific parameters, add your GBM samples (should be 6 of them)\n",
    "samples = [\n",
    "                {\n",
    "            \"sample_id\": \"INT_C102\",\n",
    "        \"gene_matrix_path\": \"/group/sottoriva/alexandra.livanova/INT/multiome/INT_C102_T3/data/INT_C102_T3_gene_matrix.h5ad\",\n",
    "        \"atac_fragments_path\": \"/group/sottoriva/00-PROCESSED_DATA/2023-INT/INT_C102/INT_C102/INT_C102_T/INT_C102_T3/multiome/LAZ_01033/atac_fragments.tsv.gz\",\n",
    "        \"output_snap_path\": \"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_normal_integration/samples_to_merge/INT_C102_snap.h5ad\"\n",
    "    },  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2123ab-1f28-4d53-8b81-33f9c9cdaa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each sample\n",
    "for sample in samples:\n",
    "    process_sample(**sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e194a-f02c-48fb-8359-adf7e97e89ea",
   "metadata": {},
   "source": [
    "## Step 2. Aggregate your ATAC objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808c529-199e-4313-840a-afbe3b20f4c3",
   "metadata": {},
   "source": [
    "Now we can aggregate our pre-processed ATAC objects as soon as they contain raw data, have same features in tile matrices, and same obs columns. This step I do in sbatch code as soon as it is impossible to aggregate such huge tables in interactive session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984996ee-957c-4d8f-b042-4126d758e2cf",
   "metadata": {},
   "source": [
    "#### In cluster I have a file like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9931457-5a59-4b11-a118-36fce664e68a",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=atac_concat       # Job name\n",
    "#SBATCH --output=atac_concat.log         # Output file\n",
    "#SBATCH --error=atac_concat.err           # Error file\n",
    "#SBATCH --time=24:00:00                   \n",
    "#SBATCH --ntasks=1                     # Number of tasks\n",
    "#SBATCH --cpus-per-task=32              # Number of CPU cores per task\n",
    "#SBATCH --mem=256G                       # Memory per node\n",
    "\n",
    "source ~/.bashrc\n",
    "conda activate atac_env_310\n",
    "\n",
    "python atac_concat.py\n",
    "\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab933b3-de46-438f-82ea-3182bc56c2ec",
   "metadata": {},
   "source": [
    "#### this file runs python file like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837205fe-a4ed-4c92-b548-720b9f48294c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "import anndata as ad\n",
    "import snapatac2 as snap\n",
    "import scanpy as sc\n",
    "import os\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "data02b2=sc.read(\"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_002_B2_snap.h5ad\")\n",
    "data02=sc.read('/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_002_S1_snap.h5ad')\n",
    "data_06=sc.read(\"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_006_S1_snap.h5ad\")\n",
    "data_08=sc.read(\"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_008_S1_snap.h5ad\")\n",
    "data_11=sc.read(\"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_011_S1_snap.h5ad\")\n",
    "data_14=sc.read(\"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_014_B2_snap.h5ad\") \n",
    "data_21=sc.read(\"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_021_B2_snap.h5ad\") \n",
    "data_25_b2=sc.read(\"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_025_B2_snap.h5ad\")\n",
    "data_25=sc.read(\"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_025_S1_snap.h5ad\")\n",
    "data_31=sc.read(\"/group/sottoriva/alexandra.livanova/INT/multiome/CRC_integration/ATAC_UNICORN_integration/samples_to_integrate/U01_031_B2_snap.h5ad\")\n",
    "\n",
    "atac_data=ad.concat([data02b2, data02])\n",
    "atac_data=ad.concat([atac_data, data_06])\n",
    "atac_data=ad.concat([atac_data, data_08])\n",
    "atac_data=ad.concat([atac_data, data_11])\n",
    "atac_data=ad.concat([atac_data, data_14])\n",
    "atac_data=ad.concat([atac_data, data_21])\n",
    "atac_data=ad.concat([atac_data, data_25_b2])\n",
    "atac_data=ad.concat([atac_data, data_25])\n",
    "atac_data=ad.concat([atac_data, data_31])\n",
    "\n",
    "atac_data.write(\"/group/sottoriva/alexandra.livanova/INT/multiome/unicorn_atac_all_snap2.h5ad\")\n",
    "\n",
    "data = snap.read('/group/sottoriva/alexandra.livanova/INT/multiome/unicorn_atac_all_snap2.h5ad')\n",
    "        \n",
    "snap.pp.select_features(data, n_features=25000)\n",
    "        \n",
    "snap.tl.spectral(data, n_comps=30)\n",
    "        \n",
    "snap.tl.umap(data)\n",
    "\n",
    "data.close()\n",
    "\n",
    "data = snap.read('/group/sottoriva/alexandra.livanova/INT/multiome/unicorn_atac_all_snap2.h5ad')\n",
    "\n",
    "snap.tl.leiden(data)\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75a5f2-3f49-44ae-b2c2-5ce50a9a332c",
   "metadata": {},
   "source": [
    "## Step 3. Peak calling and differential accessibility test + motif enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f76e8c-ff66-4ceb-9e89-ac39006ab99a",
   "metadata": {},
   "source": [
    "By this moment you have aggregated anndata with all samples together. You can run peak calling and DA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987206b8-9bc5-4dfc-8366-91ebf1e2b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change these paths\n",
    "input_dir = \"\" #folder with aggregated adata\n",
    "output_peak_mat_dir = \"\"\n",
    "output_diff_peaks_dir = \"\"\n",
    "output_motifs_tumor_dir = \"\"\n",
    "output_motifs_normal_dir = \"\"\n",
    "\n",
    "# create paths if they do not exist\n",
    "os.makedirs(output_peak_mat_dir, exist_ok=True)\n",
    "os.makedirs(output_diff_peaks_dir, exist_ok=True)\n",
    "os.makedirs(output_motifs_tumor_dir, exist_ok=True)\n",
    "os.makedirs(output_motifs_normal_dir, exist_ok=True)\n",
    "\n",
    "# There is an adata with uns['reference_sequences'] inside, i have to use it because mine was lost during the aggregation\n",
    "data_ref=snap.read(\"/group/sottoriva/alexandra.livanova/UNICORN/multiome/U01_002S1_T3/data/U01_002_snap.h5ad\")\n",
    "\n",
    "\n",
    "# Process all .h5ad files in the input directory\n",
    "\n",
    "files=[\n",
    "\n",
    "    'INT_C128_snap_with_normal_all.h5ad' #your aggregated adata in input folder\n",
    "]\n",
    "for file in files:\n",
    "    input_path = os.path.join(input_dir, file)\n",
    "    print(f\"Processing: {file}\")\n",
    "\n",
    "    # Read the dataset and transfer the ref sequences (very stupid thing but must be done)\n",
    "    data = snap.read(input_path)\n",
    "    data.uns['reference_sequences']=data_ref.uns['reference_sequences']\n",
    "    data_ref.close()\n",
    "\n",
    "    # Call peaks by groups\n",
    "    print(\"Peak calling...\")\n",
    "    snap.tl.macs3(data, groupby='celltype_from_atac')\n",
    "    print(\"Peak merging...\")\n",
    "    peaks = snap.tl.merge_peaks(data.uns['macs3'], snap.genome.hg38)\n",
    "\n",
    "    # Create peak matrix\n",
    "    print(\"Peak matrix is being created...\")\n",
    "    peak_mat = snap.pp.make_peak_matrix(data, use_rep=peaks['Peaks'])\n",
    "    peak_mat_path = os.path.join(output_peak_mat_dir, file)\n",
    "    peak_mat.write(peak_mat_path)\n",
    "\n",
    "    # Differential peak analysis\n",
    "    tumor = data.obs['celltype_from_atac'] == \"Tumor cells\"\n",
    "    epit = data.obs['celltype_from_atac'] == \"Epithelial cells\"\n",
    "    peaks_selected = np.logical_or(\n",
    "            peaks[\"Tumor cells\"].to_numpy(),\n",
    "            peaks[\"Epithelial cells\"].to_numpy(),\n",
    "        )\n",
    "    data.close()\n",
    "\n",
    "    print(\"Diff peaks test is running...\")\n",
    "    diff_peaks = snap.tl.diff_test(\n",
    "            peak_mat,\n",
    "            cell_group1=tumor,\n",
    "            cell_group2=epit,\n",
    "            features=peaks_selected,\n",
    "        )\n",
    "\n",
    "    diff_peaks_path = os.path.join(output_diff_peaks_dir, file)\n",
    "    write_dataset(pd.DataFrame(diff_peaks, columns=diff_peaks.columns), diff_peaks_path)\n",
    "\n",
    "    diff_peaks = diff_peaks.filter(pl.col('adjusted p-value') < 0.01) #select significant peaks only\n",
    "\n",
    "    peaks = {\n",
    "            \"Tumor cells\": diff_peaks.filter(pl.col(\"log2(fold_change)\") > 0)['feature name'].to_numpy(),\n",
    "            \"Epithelial cells\": diff_peaks.filter(pl.col(\"log2(fold_change)\") < 0)['feature name'].to_numpy(),\n",
    "        }\n",
    "\n",
    "    # Motif enrichment analysis\n",
    "    print(\"Motif enrichment is running...\")\n",
    "    motifs = snap.tl.motif_enrichment(\n",
    "            motifs=snap.datasets.cis_bp(unique=True),\n",
    "            regions=peaks,\n",
    "            genome_fasta=snap.genome.hg38,\n",
    "        )\n",
    "\n",
    "    # Save motifs for tumor cells\n",
    "    motifs_tumor_cells = pd.DataFrame({\n",
    "            'index': motifs[\"Tumor cells\"]['name'].to_list(),\n",
    "            'LFC': motifs[\"Tumor cells\"]['log2(fold change)'].to_list(),\n",
    "            'padj': motifs[\"Tumor cells\"]['adjusted p-value'].to_list()\n",
    "        }).set_index('index')\n",
    "\n",
    "    motifs_tumor_path = os.path.join(output_motifs_tumor_dir, file)\n",
    "    write_dataset(motifs_tumor_cells, motifs_tumor_path)\n",
    "\n",
    "    # Save motifs for normal cells\n",
    "    motifs_normal_cells = pd.DataFrame({\n",
    "            'index': motifs[\"Epithelial cells\"]['name'].to_list(),\n",
    "            'LFC': motifs[\"Epithelial cells\"]['log2(fold change)'].to_list(),\n",
    "            'padj': motifs[\"Epithelial cells\"]['adjusted p-value'].to_list()\n",
    "        }).set_index('index')\n",
    "\n",
    "    motifs_normal_path = os.path.join(output_motifs_normal_dir, file)\n",
    "    write_dataset(motifs_normal_cells, motifs_normal_path)\n",
    "\n",
    "    # Close the dataset\n",
    "\n",
    "    print(f\"Finished processing: {file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atac_env_310]",
   "language": "python",
   "name": "conda-env-atac_env_310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
